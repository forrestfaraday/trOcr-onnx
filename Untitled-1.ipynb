{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from onnxruntime import get_available_providers\n",
    "from onnx_trocr_inference import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['TensorrtExecutionProvider', 'CUDAExecutionProvider', 'CPUExecutionProvider']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get onnxruntime providers\n",
    "get_available_providers()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Could not find image processor class in the image processor config or the model config. Loading based on pattern matching with the model's feature extractor configuration.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model_name = \"microsoft/trocr-base-handwritten\"\n",
    "processor = TrOCRProcessor.from_pretrained(model_name)\n",
    "model = VisionEncoderDecoderModel.from_pretrained(model_name)\n",
    "\n",
    "# load image from the IAM dataset\n",
    "url = \"https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcTy8XVkFVffEiSZLjWFgn_ZDm3JF55TglkUgQ&usqp=CAU \"\n",
    "image = Image.open(requests.get(url, stream=True).raw).convert(\"RGB\")\n",
    "pixel_values = processor([image], return_tensors=\"pt\").pixel_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Could not find image processor class in the image processor config or the model config. Loading based on pattern matching with the model's feature extractor configuration.\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/home/forest/miniconda3/envs/ort/lib/python3.9/site-packages/torch/cuda/__init__.py:88: UserWarning: CUDA initialization: CUDA unknown error - this may be due to an incorrectly set up environment, e.g. changing env variable CUDA_VISIBLE_DEVICES after program start. Setting the available devices to be zero. (Triggered internally at ../c10/cuda/CUDAFunctions.cpp:109.)\n",
      "  return torch._C._cuda_getDeviceCount() > 0\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/forest/miniconda3/envs/ort/lib/python3.9/site-packages/transformers/generation/utils.py:1387: UserWarning: Neither `max_length` nor `max_new_tokens` has been set, `max_length` will default to 20 (`self.config.max_length`). Controlling `max_length` via the config is deprecated and `max_length` will be removed from the config in v5 of Transformers -- we recommend using `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original time:  2.592599868774414 Run Wild\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Could not find image processor class in the image processor config or the model config. Loading based on pattern matching with the model's feature extractor configuration.\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA unknown error - this may be due to an incorrectly set up environment, e.g. changing env variable CUDA_VISIBLE_DEVICES after program start. Setting the available devices to be zero.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 37\u001b[0m\n\u001b[1;32m     33\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mOriginal time: \u001b[39m\u001b[39m\"\u001b[39m, end \u001b[39m-\u001b[39m start, model_output)\n\u001b[1;32m     36\u001b[0m test_original()\n\u001b[0;32m---> 37\u001b[0m test_ort()\n",
      "Cell \u001b[0;32mIn[4], line 13\u001b[0m, in \u001b[0;36mtest_ort\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m model\u001b[39m.\u001b[39mconfig\u001b[39m.\u001b[39mpad_token_id \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mconfig\u001b[39m.\u001b[39mdecoder\u001b[39m.\u001b[39mpad_token_id \u001b[39m=\u001b[39m processor\u001b[39m.\u001b[39mtokenizer\u001b[39m.\u001b[39mpad_token_id\n\u001b[1;32m     11\u001b[0m model\u001b[39m.\u001b[39mconfig\u001b[39m.\u001b[39meos_token_id \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mconfig\u001b[39m.\u001b[39mdecoder\u001b[39m.\u001b[39meos_token_id \u001b[39m=\u001b[39m processor\u001b[39m.\u001b[39mtokenizer\u001b[39m.\u001b[39msep_token_id\n\u001b[0;32m---> 13\u001b[0m generated_ids \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mgenerate(pixel_values\u001b[39m.\u001b[39;49mto(device))\n\u001b[1;32m     15\u001b[0m end \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime()\n\u001b[1;32m     17\u001b[0m model_output \u001b[39m=\u001b[39m processor\u001b[39m.\u001b[39mtokenizer\u001b[39m.\u001b[39mbatch_decode(generated_ids, skip_special_tokens\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, device\u001b[39m=\u001b[39mdevice)[\u001b[39m0\u001b[39m]\n",
      "File \u001b[0;32m~/miniconda3/envs/ort/lib/python3.9/site-packages/torch/cuda/__init__.py:229\u001b[0m, in \u001b[0;36m_lazy_init\u001b[0;34m()\u001b[0m\n\u001b[1;32m    227\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39m'\u001b[39m\u001b[39mCUDA_MODULE_LOADING\u001b[39m\u001b[39m'\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m os\u001b[39m.\u001b[39menviron:\n\u001b[1;32m    228\u001b[0m     os\u001b[39m.\u001b[39menviron[\u001b[39m'\u001b[39m\u001b[39mCUDA_MODULE_LOADING\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mLAZY\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m--> 229\u001b[0m torch\u001b[39m.\u001b[39;49m_C\u001b[39m.\u001b[39;49m_cuda_init()\n\u001b[1;32m    230\u001b[0m \u001b[39m# Some of the queued calls may reentrantly call _lazy_init();\u001b[39;00m\n\u001b[1;32m    231\u001b[0m \u001b[39m# we need to just return without initializing in that case.\u001b[39;00m\n\u001b[1;32m    232\u001b[0m \u001b[39m# However, we must not let any *other* threads in!\u001b[39;00m\n\u001b[1;32m    233\u001b[0m _tls\u001b[39m.\u001b[39mis_initializing \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA unknown error - this may be due to an incorrectly set up environment, e.g. changing env variable CUDA_VISIBLE_DEVICES after program start. Setting the available devices to be zero."
     ]
    }
   ],
   "source": [
    "def test_ort():\n",
    "    processor = TrOCRProcessor.from_pretrained(model_name)\n",
    "    model = ORTModelForVision2Seq()\n",
    "    model = model.to(device)\n",
    "\n",
    "    start = time.time()\n",
    "\n",
    "    model.config.decoder_start_token_id = 2\n",
    "    model.config.vocab_size = model.config.decoder.vocab_size\n",
    "    model.config.pad_token_id = model.config.decoder.pad_token_id = processor.tokenizer.pad_token_id\n",
    "    model.config.eos_token_id = model.config.decoder.eos_token_id = processor.tokenizer.sep_token_id\n",
    "\n",
    "    generated_ids = model.generate(pixel_values.to(device))\n",
    "\n",
    "    end = time.time()\n",
    "\n",
    "    model_output = processor.tokenizer.batch_decode(generated_ids, skip_special_tokens=True, device=device)[0]\n",
    "\n",
    "    print(\"ORT time: \", end - start, model_output)\n",
    "\n",
    "\n",
    "def test_original():\n",
    "    processor = TrOCRProcessor.from_pretrained(model_name)\n",
    "    model = VisionEncoderDecoderModel.from_pretrained(model_name)\n",
    "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "    print(device)\n",
    "    start = time.time()\n",
    "    generated_ids = model.generate(pixel_values.to(device))\n",
    "    end = time.time()\n",
    "\n",
    "    model_output = processor.batch_decode(generated_ids, skip_special_tokens=True)[0]\n",
    "\n",
    "    print(\"Original time: \", end - start, model_output)\n",
    "\n",
    "\n",
    "test_original()\n",
    "test_ort()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch \n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ort",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3c3e05ff27fc98a91ae76f0551d628de3e89010ccf719267306f9ed11c6df735"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
